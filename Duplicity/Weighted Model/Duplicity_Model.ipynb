{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries, Dataset, and Installation of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in e:\\python\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in e:\\python\\lib\\site-packages (from sentence-transformers) (4.34.1)\n",
      "Requirement already satisfied: tqdm in e:\\python\\lib\\site-packages (from sentence-transformers) (4.50.2)\n",
      "Requirement already satisfied: torch>=1.6.0 in e:\\python\\lib\\site-packages (from sentence-transformers) (2.0.1)\n",
      "Requirement already satisfied: torchvision in e:\\python\\lib\\site-packages (from sentence-transformers) (0.15.2)\n",
      "Requirement already satisfied: numpy in e:\\python\\lib\\site-packages (from sentence-transformers) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn in e:\\python\\lib\\site-packages (from sentence-transformers) (1.1.3)\n",
      "Requirement already satisfied: scipy in e:\\python\\lib\\site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: nltk in e:\\python\\lib\\site-packages (from sentence-transformers) (3.5)\n",
      "Requirement already satisfied: sentencepiece in e:\\python\\lib\\site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in e:\\python\\lib\\site-packages (from sentence-transformers) (0.17.3)\n",
      "Requirement already satisfied: filelock in e:\\python\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.4)\n",
      "Requirement already satisfied: fsspec in e:\\python\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: requests in e:\\python\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\python\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (5.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\python\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.4.0)\n",
      "Requirement already satisfied: packaging>=20.9 in e:\\python\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n",
      "Requirement already satisfied: sympy in e:\\python\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (1.6.2)\n",
      "Requirement already satisfied: networkx in e:\\python\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (2.5)\n",
      "Requirement already satisfied: jinja2 in e:\\python\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (2.11.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\python\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2020.10.15)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in e:\\python\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in e:\\python\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.0)\n",
      "Requirement already satisfied: click in e:\\python\\lib\\site-packages (from nltk->sentence-transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in e:\\python\\lib\\site-packages (from nltk->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in e:\\python\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in e:\\python\\lib\\site-packages (from torchvision->sentence-transformers) (10.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in e:\\python\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\john wick\\appdata\\roaming\\python\\python38\\site-packages (from networkx->torch>=1.6.0->sentence-transformers) (5.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\python\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\python\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\python\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\python\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in e:\\python\\lib\\site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (e:\\python\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (e:\\python\\lib\\site-packages)\n",
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "DEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import unicodedata\n",
    "from emoji import demojize\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "df = pd.read_excel('Chips_Database.xlsx')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title                         object\n",
      "Company                       object\n",
      "Description                   object\n",
      "Salary                        object\n",
      "Deadline              datetime64[ns]\n",
      "Locations                     object\n",
      "Mode                          object\n",
      "Type                          object\n",
      "Gender                        object\n",
      "Experience                    object\n",
      "Field_Of_Interests            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clean(text_data, stop_words, lemmatizer):\n",
    "    text_data = unicodedata.normalize('NFKD', text_data).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    text_data = text_data.lower()\n",
    "    text_data = demojize(text_data)\n",
    "    pattern_punct = re.compile(r'([.,/#!$%^&*?;:{}=_`~()+-])\\1{1,}')\n",
    "    text_data = pattern_punct.sub(r'\\1', text_data)\n",
    "    text_data = re.sub(' {2,}',' ', text_data)\n",
    "    text_data = re.sub(r\"[^a-zA-Z?!]+\", ' ', text_data)\n",
    "    text_data = str(text_data)\n",
    "    tokenizer = ToktokTokenizer()\n",
    "    text_data = tokenizer.tokenize(text_data)\n",
    "    text_data = [item for item in text_data if item not in stop_words]\n",
    "    text_data = [lemmatizer.lemmatize(word = w, pos = 'v') for w in text_data]\n",
    "    text_data = ' '.join (text_data)\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "def cosine_similarity(sentences):\n",
    "    #Job title is 5 points, fields_of_interests is 3 points, description is 2 points, experience is useless since no interpretation\n",
    "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    \n",
    "    embedding_1 = model.encode(sentences[0], convert_to_tensor = True)\n",
    "    \n",
    "    similarities = []\n",
    "    \n",
    "    for sentence in sentences[1:]:\n",
    "        embedding_2 = model.encode(sentence, convert_to_tensor=True)\n",
    "        \n",
    "        similarity = util.pytorch_cos_sim(embedding_1, embedding_2)\n",
    "        similarities.append(similarity.item())\n",
    "    \n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataframe(df, company, deadline, locations, mode, type_, gender):\n",
    "    location_set = set(locations)\n",
    "    df['Deadline'] = pd.to_datetime(df['Deadline'], format='%d-%m-%Y')\n",
    "    \n",
    "    filtered_df = df[\n",
    "        (df['Company'] == company) &\n",
    "        (df['Locations'].apply(lambda x: x in location_set)) &  # Check if location is in the list\n",
    "        (df['Mode'] == mode) &\n",
    "        (df['Type'] == type_) &\n",
    "        (df['Gender'] == gender) &\n",
    "        (df['Deadline'] >= pd.to_datetime(deadline, format='%d-%m-%Y'))\n",
    "    ]\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with Chips Database Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Job Title: Data Analyst\n",
      "Enter Company Name:Herbion Private Limited\n",
      "Enter Description:Needs to know SQL, Excel, Tableau\n",
      "Enter Salary:40,000\n",
      "Enter a location (or 'stop' to quit): Karachi\n",
      "Enter a location (or 'stop' to quit): stop\n",
      "Enter Job Mode:Physical\n",
      "Enter Job Type:Full-time\n",
      "Enter Gender:All\n",
      "Enter Experience:2\n",
      "Enter a field of interest (or 'stop' to quit): Python\n",
      "Enter a field of interest (or 'stop' to quit): R\n",
      "Enter a field of interest (or 'stop' to quit): Node JS\n",
      "Enter a field of interest (or 'stop' to quit): stop\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Deadline</th>\n",
       "      <th>Locations</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Type</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Field_Of_Interests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Herbion Private Limited</td>\n",
       "      <td>Job Summary: Seeking a skilled and motivated D...</td>\n",
       "      <td>Rs 60,000 - Rs 80,000 a month</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>Karachi</td>\n",
       "      <td>Physical</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>All</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Data Science, Supply Chain, Predictive Modelin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Title                  Company  \\\n",
       "0  Data Scientist  Herbion Private Limited   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Job Summary: Seeking a skilled and motivated D...   \n",
       "\n",
       "                          Salary   Deadline Locations      Mode       Type  \\\n",
       "0  Rs 60,000 - Rs 80,000 a month 2023-06-30   Karachi  Physical  Full-time   \n",
       "\n",
       "  Gender Experience                                 Field_Of_Interests  \n",
       "0    All    Unknown  Data Science, Supply Chain, Predictive Modelin...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = input(\"Enter Job Title: \")\n",
    "company = input(\"Enter Company Name:\")\n",
    "description = input(\"Enter Description:\")\n",
    "salary = input(\"Enter Salary:\") + \" a month\"\n",
    "#deadline = input(\"Enter Deadline:\")\n",
    "deadline = \"01-01-2020\"\n",
    "locations = []\n",
    "while True:\n",
    "    location = input(\"Enter a location (or 'stop' to quit): \")\n",
    "    if location.lower() == 'stop':\n",
    "        break\n",
    "    locations.append(location)\n",
    "mode = input(\"Enter Job Mode:\")\n",
    "type_ = input(\"Enter Job Type:\")\n",
    "gender = input(\"Enter Gender:\")\n",
    "experience = input(\"Enter Experience:\") + \" years\"\n",
    "fields_of_interests = []\n",
    "while True:\n",
    "    fields_of_interest = input(\"Enter a field of interest (or 'stop' to quit): \")\n",
    "    if fields_of_interest.lower() == 'stop':\n",
    "        break\n",
    "    fields_of_interests.append(fields_of_interest)\n",
    "filtered_df = filter_dataframe(df, company, deadline, locations, mode, type_, gender)\n",
    "\n",
    "filtered_df\n",
    "\n",
    "# ENTER IN THIS FORMAT\n",
    "# Enter Job Title: Data Analyst\n",
    "# Enter Company Name:Herbion Private Limited\n",
    "# Enter Description:Needs to know SQL, Excel, Tableau\n",
    "# Enter Salary:40,000\n",
    "# Enter a location (or 'stop' to quit): Karachi\n",
    "# Enter a location (or 'stop' to quit): stop\n",
    "# Enter Job Mode:Physical\n",
    "# Enter Job Type:Full-time\n",
    "# Enter Gender:All\n",
    "# Enter Experience:2\n",
    "# Enter a field of interest (or 'stop' to quit): Python\n",
    "# Enter a field of interest (or 'stop' to quit): R\n",
    "# Enter a field of interest (or 'stop' to quit): Node JS\n",
    "# Enter a field of interest (or 'stop' to quit): stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5058190226554871]\n"
     ]
    }
   ],
   "source": [
    "csv_titles = filtered_df['Title'].tolist()\n",
    "titles = [title] + csv_titles\n",
    "#print(titles)\n",
    "\n",
    "score = cosine_similarity(titles)\n",
    "total_score = [x * 0.5 for x in score] # Giving Title as weight 0.5\n",
    "\n",
    "csv_description = filtered_df['Description'].tolist()\n",
    "descriptions = [description] + csv_description\n",
    "\n",
    "for i in range(len(score)):\n",
    "    clean_descriptions = [text_clean(description, stop_words, lemmatizer) for description in descriptions]\n",
    "    score = cosine_similarity(clean_descriptions)\n",
    "#     score = cosine_similarity(descriptions)\n",
    "    total_score[i] += score[i] * 0.2 # Giving Description as weight 0.2\n",
    "\n",
    "\n",
    "csv_foi = filtered_df['Field_Of_Interests'].tolist()\n",
    "foi = ', '.join(fields_of_interests)\n",
    "fois = [foi] + csv_foi\n",
    "\n",
    "for i in range(len(score)):\n",
    "    score = cosine_similarity(fois)\n",
    "    total_score[i] += score[i] * 0.3 # Giving Field Of Interests as weight 0.3\n",
    "print(total_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison Between Two Chips Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [\"Web Developer - Node JS\", \"Web Developer - Node JS\"]\n",
    "descriptions = [\"Should know the basics of Node JS, knowledge of APIS is a good plus\", \"Dedicated professional who can design amazing webpages using Node JS\"]\n",
    "fois = [\"Node JS, Javascript, Backend\", \"Node JS, Javascript, Web Developer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'y' to restart: y\n",
      "\n",
      "Title Percentage:  0.5000000596046448 %\n",
      "\n",
      "Description Percentage:  0.09553024768829346 %\n",
      "\n",
      "Field Of Interest Percentage:  0.2424574255943298 %\n",
      "\n",
      "Accuracy:  0.837987732887268 %\n"
     ]
    }
   ],
   "source": [
    "if input(\"Press 'y' to restart: \") != 'y':\n",
    "    for j in range(2):\n",
    "        titles = []\n",
    "        titles.append(input(\"Add a title for chip: \"))\n",
    "\n",
    "        descriptions = []\n",
    "        descriptions.append(input(\"Add description for chip: \"))\n",
    "\n",
    "        fois = []\n",
    "        fois.append(input(\"Add fois for chip (Python, R, SQL): \"))\n",
    "\n",
    "score = cosine_similarity(titles)\n",
    "total_score = [x * 0.5 for x in score]  # Giving Title as weight 0.5\n",
    "print(\"\\nTitle Percentage: \", total_score[0], \"%\")\n",
    "\n",
    "clean_descriptions = [text_clean(description, stop_words, lemmatizer) for description in descriptions]\n",
    "score = cosine_similarity(clean_descriptions)\n",
    "total_score[0] += score[0] * 0.2  # Giving Description as weight 0.2\n",
    "print(\"\\nDescription Percentage: \", score[0] * 0.2, \"%\")\n",
    "\n",
    "score = cosine_similarity(fois)\n",
    "total_score[0] += score[0] * 0.3  # Giving Field Of Interest as weight 0.3\n",
    "print(\"\\nField Of Interest Percentage: \", score[0] * 0.3, \"%\")\n",
    "\n",
    "print(\"\\nAccuracy: \", total_score[0], \"%\")\n",
    "\n",
    "# Add a title for chip: Backend Developer\n",
    "# Add description for chip: Should know the basics of Node JS, knowledge of APIS is a good plus\n",
    "# Add fois for chip (Python, R, SQL): Node JS, Javascript, Backend\n",
    "# Add a title for chip: Web Developer - Node JS\n",
    "# Add description for chip: Dedicated professional who can design amazing webpages using Node JS\n",
    "# Add fois for chip (Python, R, SQL): Node JS, Java, Web Developer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
